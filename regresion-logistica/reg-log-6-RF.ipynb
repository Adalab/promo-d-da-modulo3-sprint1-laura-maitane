{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ejercicios de pair programming M칩dulo 3 Sprint 1**\n",
    "## **Regresi칩n Logistica: Lecci칩n 6 - Randon Forest**\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# Gr치ficos\n",
    "# ------------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelado y evaluaci칩n\n",
    "# ------------------------------------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score , cohen_kappa_score, roc_curve,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Configuraci칩n warnings\n",
    "# ------------------------------------------------------------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora hemos ajustado el modelo usando una Regresi칩n Log칤stica, pero como hemos aprendido, podemos usar el Random Forest en este tipo de problemas. Los objetivos de este pair programming:\n",
    "\n",
    "\n",
    "Ajustad un modelo de Random Forest a nuestros datos.\n",
    "\n",
    "- Calculad las m칠tricas a nuestro nuevo modelo.\n",
    "  \n",
    "- Comparad las m칠tricas con los modelos hechos hasta ahora. 쮺u치l es mejor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos los datos en X e y\n",
    "\n",
    "X1 = df.drop(\"satisfaction\", axis = 1)\n",
    "y1 = df[\"satisfaction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y dividir nuestros datos en train y test para poder evaluar la bondad de nuestro modelo\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X1, y1, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo primero que tenemos que hacer es definir un diccionario con los hiperpar치metros que queremos modificar y los valores que queremos \n",
    "\n",
    "param = {\"max_depth\": [2,4, 6, 10, 12, 14], # teniendo en cuenta que ten칤amos overfitting tendremos que reducir la profundidad del modelo, la nuestra anterior era de 17. Bajaremos mucho este valor ya que ten칤amos un overfitting muy claro\n",
    "        \"max_features\": [1,2,3,4],# calculamos en celdas anteriores, probaremos a hacer el modelo como una variable, 2, 3 y 4. Ponemos como l칤mite el 4 ya que es el resultado de la raiz cuadrada. \n",
    "        # estos dos hiperpar치metros son m치s dif칤ciles de definir, pero usualmente se suelen elegir los siguientes valores\n",
    "        \"min_samples_split\": [10, 50, 100],\n",
    "        \"min_samples_leaf\": [10,50,100]} "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_rf = GridSearchCV(\n",
    "            estimator=RandomForestClassifier(random_state=42), # tipo de modelo que queremos hacer\n",
    "            param_grid= param, # que hiperpar치metros queremos que testee\n",
    "            cv=10, # crossvalidation que aprendimos en la lecci칩n de regresi칩n lineal intro. \n",
    "            verbose=-1) # para que no nos printee ning칰n mensaje en pantalla\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustamos el modelo que acabamos de definir en el GridSearch\n",
    "# 游뚿 Esta celda puede tardar en ejecutarse\n",
    "\n",
    "gs_rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saquemos ahora cual es nuestro mejor bosque\n",
    "\n",
    "bosque = gs_rf.best_estimator_\n",
    "bosque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dibujemos los 치rboles de nuestro bosque\n",
    "\n",
    "for arbol in tqdm(bosque.estimators_):\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    tree.plot_tree(arbol, feature_names= x_train.columns, filled = True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
